## Frequentist {#sec:freq}

After introducing some common statistical notions in the previous sections, we can now focus on linear models and their corresponding statistical tests.
From linear models, it is possible to formulate many common tests, or very close approximations, including Pearson correlations, t-tests and ANOVAs [@lindelov2019common].
Note that linear models are as valid in the Bayesian paradigm as in the frequentist paradigm.
However, here we focus on the combination with the frequentists tests, which is why these models are listed under the frequentist section.

In line with @bishop2006pattern, generally, we can write a linear model $\text{lm}$ as

$$ \text{lm}(X_{v}, W_{m}) = w_0 + w_1 x_1 + ... + w_m x_v, $$

with input variables $X_v$ and weights $W_m$.
Note that this means that the data with $n$ measurements can be stored in a $n \times v$ matrix.
For the rest of this chapter, we assume that the errors are Gaussian.

### One sample

Say that you have a vector of sample values `A` and want to test whether the mean of the population is $x$.
Lets denote the mean of the population and sample respectively by $\mu$ and $\mu_s$ and, for illustration purposes, lets generate some data:

```{.include}
_gen/one_sample_data-sc.md
```

which is visualized in @fig:plot_one_sample_data.

```{.include}
_gen/plot_one_sample_data.md
```

Okay, so let's say that we want to know whether this data was generated by a process having $\mu_0$; this is our null hypothesis and we want to check whether the data is significantly different, that is, we want to test whether $\mu \neq \mu_0$.
A simple way to guess $\mu$ is to take the mean of the sample.
However, these means on their own don't provide much insight into **how** likely it is that $\mu = \mu_0$, see @fig:plot_one_sample_data_mean.

```{.include}
_gen/plot_one_sample_data_mean.md
```

To estimate this, we can guess the distribution of the sample.
As already stated, we assume that data is generated from a normal distribution and we can use the sample mean and standard deviation to guess the distribution parameters.
This distribution is depicted in @fig:plot_one_sample_data_distribution.

```{.include}
_gen/plot_one_sample_data_distribution.md
```

Now that we have this distribution, we could come up with a formal conclusion.
For example, we can say that $\mu = \mu_s$ if $\mu_s$ lies within the 95% confidence interval of the estimated distribution.
Then, in this case, we would now conclude that the means do not significantly differ.

Unfortunately, for small samples, the normal distribution isn't good enough.
This is due to the fact that ...


$$ \text{one\_sample}(X_v, W) = w_0 $$

```{.include}
_gen/one_sample_tests.md
```

